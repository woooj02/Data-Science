{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Branded_Logo_CUDenver.PNG\" width=\"150\">\n",
    "\n",
    "## <center>CSCI 4580/5580 - Data Science – Spring 2022</center>\n",
    "<center>Lab 7: Logistic Regression and Random Forests</center><center><font color='red'>Deadline: April 25, 2022 - 11:59 PM</font></center><center>Total Points: 100</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Please note that this lab must be done individually. By submitting this lab, you certify that this is your own work, your code will be checked against other submissions and resources using automatic tools. Everyone should be getting a hands on experience in this course. You are free to discuss course material with fellow students, and we encourage you to use Internet resources to aid your understanding, but the work you turn in, including all code and answers, must be your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "You need to submit a single .ipynb file on Canvas, named your-lastname_your-first-name.ipynb. For example, if your name is John Smith, you should name the file smith_john.ipynb.\n",
    "- Please do not include extra files such as the input datasets in your submission.\n",
    "- Answer Questions 1 - 7 in the designated cells. Please do not add or remove any cells. \n",
    "- Please download your submission file after submission and make sure it is not corrupted. Use the 'Run All' option from the 'Cell' menu to ensure all cells run without any issues. We will not be responsible for corrupted submissions and will not take a resubmission after the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need Help?\n",
    "If you need help with this lab, please email me at sundous.hussein@ucdenver.edu or come to my office hours. We also encourage you to ask your questions on the designated channel for the lab on Microsoft Teams. This way, you may receive assistance from your classmates that might’ve ran through the same issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given enough data, Logisitic Regression should always do at least as well as Naive Bayes on binary-feature data. Let's try that out on the text dataset (named <b>words</b>) that can be downloaded from Canvas under Lab 7. Place it in the same directory as this notebook and unzip it.\n",
    "\n",
    "We'll also need the <b>MNIST</b> data from the last lab (Lab 6, but also available under Lab 7). Download it from Canvas and put it under the same directory as this notebook and unzip it.\n",
    "\n",
    "First, load the text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "iwords = np.loadtxt(\"words.imat.txt\")          # training data matrix in nnz x 3 form - rows are (doc, word, count) triples\n",
    "traincats = np.loadtxt(\"cats.imat.txt\")        # training labels in an ntrain x ncats matrix\n",
    "tiwords = np.loadtxt(\"testwords.imat.txt\")     # test data matrix in nnz x 3 form\n",
    "testcats = np.loadtxt(\"testcats.imat.txt\")     # test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data come as dense matrices with (row, col, val) triples in their rows. But they represent sparse matrices so we do the conversion next. Note that the matrix constructor uses wordcount>0 tests instead of the actual word counts which has the effect of making the word features binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sp.csr_matrix((iwords[:,2].astype(\"int\") > 0, (iwords[:,1].astype(\"int\"), iwords[:,0].astype(\"int\"))))\n",
    "ntrain = train.shape[0]\n",
    "nfeats = train.shape[1]\n",
    "\n",
    "test = sp.csr_matrix((tiwords[:,2] > 0, (tiwords[:,1], tiwords[:,0])),shape=(4000,nfeats))  # need to match the number of cols (words)\n",
    "ntdocs = test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we will concentrate on one label category, Category 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincat6 = traincats[:,6]\n",
    "testcat6 = testcats[:,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll import a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrclassifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and train it on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neoar\\.julia\\conda\\3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrclassifier.fit(train,traincat6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lrclassifier.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 1: Compute the accuracy of the predictions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91025"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code to score here (hint: this can be done in a single line of code)\n",
    "np.mean(preds == testcat6)\n",
    "\n",
    "#0.91025 is the accuracy of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 2: How does this compare with Naive Bayes? In case you don't have the results handy, lets do it here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BernoulliNB docs](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.756"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Add code to train, predict, score here (see sklearn documentation above for more info)\n",
    "\n",
    "bernoul_func = BernoulliNB()\n",
    "compare_model = bernoul_func.fit(train, traincat6)\n",
    "pred_comp = compare_model.predict(test)\n",
    "np.mean(pred_comp == testcat6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond Accuracy: ROC and AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label prediction accuracy is a useful but sometimes misleading measure. E.g., for data with 10% positives, a predictor that always says \"no\" will be 90% accurate. It is also very often useful to control the ratio of positive/negative labels to minimize a loss function. E.g., false positives are generally more acceptable in computational marketing (it means you show an ad to someone who might not be interested) than false negatives (you failed to show an ad to someone who might be interest, and might generate some revenue for you). \n",
    "\n",
    "Logistic Regression computes the probability of a label and that output is useful for both richer evaluation methods, and for making more careful tradeoffs between positives and negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC (Receiver-Operator Characteristic) curve is a very useful tool for interpreting classifier performance. See the background material here:\n",
    "https://en.wikipedia.org/wiki/Receiver_operating_characteristic .\n",
    "It shows the classifiers TPR (True-Positive Rate) vs FPR (False-Positive Rate) at various thresholds. The threshold isnt shown on the plot but can be inferred later. TPR and FPR are defined as:\n",
    "\n",
    "* TPR = TP / (TP + FN)   # based only on actual positive instances\n",
    "* FPR = FP / (FP + TN)   # based only on actual negative instances\n",
    "\n",
    "where TP = true positive, FN = false negative (actually a positive which is mislabelled), etc. \n",
    "Neither quantity involves a mix of positives and negatives. So ROC curves are insensitive to the actual ratio of positives to negatives. \n",
    "\n",
    "To use ROC, we first use a modified version of the \".predict\" method which returns label probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lrclassifier.predict_proba(test);\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From which you can see that there are 2 columns, i.e., one probability of false and one for true. Verify that the sum of every row is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preds,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the probabilities of cat6 membership = true, which is column 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds6 = preds[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we'll do a ROC plot for it. ROC plots represent the performance of a classifier over a range of possible threshold values, showing the true positive rate and false positives rates at those thresholds. In Python, do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "rc = roc_curve(testcat6, preds6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the X and Y coordinates of the ROC plot. To see it, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ef3e32d580>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rc[0],rc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 3: What is the True positive rate at an FPR of 0.2 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your response here\n",
    "# The True positive rate of FPR at 0.2 is close to 0.9 then it is increasing constantly.\n",
    "#In the plot it looks like 0.9 but the exact number can be anywhere between 0.850-0.950.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the ROC curve is sometimes too much information, especially if you want to compare performance of many classifiers or datasets. The overall performance is well-characterized by the AUC or Area Under the Curve. Which is exactly what the name suggests, the area under the blue curve. Since a ROC plot lies in a 1 x 1 square, the area is always <= 1.0. A random predictor puts positives and negatives on a diagonal line with slope = 1, and so a random predictor has AUC = 0.5\n",
    "\n",
    "Lets check the AUC for our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9637782435649894"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(testcat6, preds6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical Thinking: Interpreting AUC scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC score varies between 0.5 (random prediction) and 1.0. A common misconception is that a \"perfect\" predictor, i.e. a predictor that knows the exact probability of a label, will give a score of 1.0. That's incorrect. There are two sources of noise in the generation of a ROC plot:\n",
    "* The difference between the true and predicted probability of a label\n",
    "* The variance introduced by Bernoulli sampling to generate the label\n",
    "\n",
    "The latter is always present and depends on the distribution of label probabilities, the former depends on how good the model is. \n",
    "\n",
    "To see this, imagine a binary label distribution where each data label has a true probability of 0.5. A perfect predictor knows these probabilities but since they all the same, the sorted labels for the ROC plot would still be a random distribution of true and false. The ROC plot would have an AUC of 0.5. AUC scores very close to 1 are possible, but require that the true label distribution include a large fraction of probabilities close to either 1 or 0. That's because the variance of a Bernoulli variable is p(1-p), which is small if p is near 0 or 1. \n",
    "\n",
    "Let's estimate the ROC AUC for a perfect predictor on a similar distribution to our dataset. We can't know this distribution, but we can use the model's prediction  as an approximation to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll generate some uniform random numbers in [0,1], one for each test point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = npr.random(testcat6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll generate Bernoulli random numbers using the predictions as the underlying probability. We use the random numbers we just generated to do that. i.e. to generate a random Bernoulli variable with probability p, you generate a uniform random variable in [0,1] and test if (u < p). The probability that this test succeeds is exactly p. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (a < preds6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849487655594525"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(x, preds6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this number with the AUC you computed earlier. To be clear again what this number is, it is the score of a *perfect* label predictor with the label probability distribution that our classifier has. It is an estimate of how well our classifier could do on this dataset. \n",
    "\n",
    "This secondary AUC calculation is a useful normalizing test when interpreting AUC scores. A common mistake is to assume that a model with AUC 0.85 on dataset A is better (i.e. would score higher on a common dataset) than a model with a score of 0.70 on dataset B. This is not true. It depends strongly on the dataset. The model with score 0.70 may be generating perfect or near-perfect predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00e+00, 1.00e+00, 1.00e+00, 0.00e+00, 2.00e+00, 3.00e+00,\n",
       "        0.00e+00, 0.00e+00, 2.00e+00, 1.00e+00, 2.00e+00, 3.00e+00,\n",
       "        0.00e+00, 3.00e+00, 1.00e+00, 2.00e+00, 5.00e+00, 1.00e+01,\n",
       "        8.00e+00, 6.00e+00, 9.00e+00, 5.00e+00, 1.10e+01, 1.00e+01,\n",
       "        8.00e+00, 2.60e+01, 2.50e+01, 2.00e+01, 2.60e+01, 3.20e+01,\n",
       "        3.30e+01, 4.80e+01, 4.10e+01, 6.00e+01, 6.60e+01, 7.00e+01,\n",
       "        6.90e+01, 9.60e+01, 1.08e+02, 1.20e+02, 1.03e+02, 1.26e+02,\n",
       "        1.39e+02, 1.42e+02, 1.22e+02, 1.32e+02, 1.13e+02, 1.27e+02,\n",
       "        1.52e+02, 1.91e+03]),\n",
       " array([-1.11984875e+01, -1.09745178e+01, -1.07505480e+01, -1.05265783e+01,\n",
       "        -1.03026085e+01, -1.00786388e+01, -9.85466902e+00, -9.63069927e+00,\n",
       "        -9.40672952e+00, -9.18275977e+00, -8.95879002e+00, -8.73482027e+00,\n",
       "        -8.51085052e+00, -8.28688077e+00, -8.06291102e+00, -7.83894127e+00,\n",
       "        -7.61497151e+00, -7.39100176e+00, -7.16703201e+00, -6.94306226e+00,\n",
       "        -6.71909251e+00, -6.49512276e+00, -6.27115301e+00, -6.04718326e+00,\n",
       "        -5.82321351e+00, -5.59924376e+00, -5.37527401e+00, -5.15130426e+00,\n",
       "        -4.92733451e+00, -4.70336476e+00, -4.47939501e+00, -4.25542526e+00,\n",
       "        -4.03145551e+00, -3.80748576e+00, -3.58351601e+00, -3.35954626e+00,\n",
       "        -3.13557651e+00, -2.91160676e+00, -2.68763701e+00, -2.46366725e+00,\n",
       "        -2.23969750e+00, -2.01572775e+00, -1.79175800e+00, -1.56778825e+00,\n",
       "        -1.34381850e+00, -1.11984875e+00, -8.95879002e-01, -6.71909251e-01,\n",
       "        -4.47939501e-01, -2.23969751e-01, -1.57277374e-10]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log10(preds6),50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is an enormous range of values. Most probabilities are very close to zero or one, which is why this dataset has such a high ROC AUC score.\n",
    "\n",
    "Suppose instead we had a dataset with a less wide distribution. We can use a lognormal distribution to simulate this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob = np.minimum(npr.lognormal(-4,1,10000),1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty good model, e.g. for the range of user's probabilities of clicking on an ad. Let's look at a histogram of the log10 of the values (a direct histogram will be too squashed near 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   7.,   26.,   48.,  123.,  272.,  532.,  759., 1059., 1378.,\n",
       "        1412., 1331., 1108.,  838.,  528.,  322.,  152.,   65.,   26.,\n",
       "          12.,    2.]),\n",
       " array([-3.24008514, -3.08286541, -2.92564567, -2.76842594, -2.6112062 ,\n",
       "        -2.45398646, -2.29676673, -2.13954699, -1.98232725, -1.82510752,\n",
       "        -1.66788778, -1.51066805, -1.35344831, -1.19622857, -1.03900884,\n",
       "        -0.8817891 , -0.72456936, -0.56734963, -0.41012989, -0.25291016,\n",
       "        -0.09569042]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log10(cprob),20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's our distribution of virtual users. Notice that the values (which represent click probabilities) range over several orders of magnitude since we plotted their log10. Next we simulate users' click behavior. Once again we generate a uniform random variable u for each user, and output 1 if u < the user's click probability given by cprob. \n",
    "\n",
    "Finally we compute the AUC on that data, which is the score of a perfect predictor on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7694483528615839"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = npr.random(cprob.shape)\n",
    "x = (a < cprob)\n",
    "roc_auc_score(x, cprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's the AUC score for a perfect predictor on this (artificial) dataset. This is lower than the *real* predictions on the RCV1 text dataset. So be careful when interpreting AUC scores. There is no absolute scale for them, and they depend a lot on the dataset.\n",
    "\n",
    "Another important point is that the AUC value for mid-range scores can have quite a lot of variance. Try re-evaluating the last cell to see what happens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 4: What changes do you think you should make to the distribution \n",
    "cprob to increase the ROC AUC score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nChoosing a different sample and refitting our model could produce more better score.\\nAlso since the AUC score is majorly used for binary values, we can use binary classifier\\ninstead of the probabilities. Here is a better refrence for how ROC AUC issues come up:\\nhttps://medium.com/hiredscore-engineering/7-things-you-should-know-about-roc-auc-b4389ea2b2e3\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your response here\n",
    "\"\"\"\n",
    "Choosing a different sample and refitting our model could produce more better score.\n",
    "Also since the AUC score is majorly used for binary values, we can use binary classifier\n",
    "instead of the probabilities. Here is a better refrence for how ROC AUC issues come up:\n",
    "https://medium.com/hiredscore-engineering/7-things-you-should-know-about-roc-auc-b4389ea2b2e3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests are an extremely accurate classifier for datasets of moderate size. Let's try them out here. We'll load the MNIST data now, but first its probably a good idea to restart your kernel to reduce memory use. Click on the \"Kernel\" menu above and then \"Restart\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0=np.loadtxt(\"train.fmat.txt\")\n",
    "test0=np.loadtxt(\"test.fmat.txt\")\n",
    "train = np.transpose(train0[:,0:4000])\n",
    "test = np.transpose(test0[:,0:2000])\n",
    "traincats = np.loadtxt(\"ictrain.imat.txt\")\n",
    "testcats = np.loadtxt(\"ictest.imat.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're going to tuning the parameters of RFs on some test data, we need to split our test set into a validation set and a final test set to avoid overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = test[0:1000,:]\n",
    "finaltest = test[1000:2000,:]\n",
    "validationcats = testcats[0:1000]\n",
    "finaltestcats = testcats[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=30, n_estimators=20, n_jobs=4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=30,n_estimators=20,n_jobs=4,bootstrap=True)\n",
    "rfclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.879"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "np.mean(preds == validationcats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the [scikit-learn documentation for Random Forests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier) to make sure you understand the meaning of all the parameters in the call to the RandForestClassifier constructor. Which ones do you think will improve accuracy the most? **NOTE** you don't need to tune n_jobs. Its the number of threads that the classifier code runs and it only affects running time. It should be set to the number of cores that your processor has. \n",
    "\n",
    "Try tuning the classifier with the validation set above to get better than 90% accuracy on the validation set. Don't touch the final test set until you're done tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 5: Make a table with at least two values you tried each for criterion, max_features, n_estimators, and bootstrap. What trends to you notice for each one? \n",
    "\n",
    "> Question 6: Report your validation and final test accuracy. Include all the parameters you used, e.g., include the line where you invoked the RandomForestClassifier constructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criterion</th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>bootstrap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entropy</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entropy</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entropy</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>entropy</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entropy</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Criterion  max_features  n_estimators  bootstrap\n",
       "0   entropy             9            13       True\n",
       "1      gini             9            13       True\n",
       "2      gini            17            43      False\n",
       "3      gini            18            43      False\n",
       "4   entropy             9            45      False\n",
       "5   entropy             9            45       True\n",
       "6   entropy            17            45      False\n",
       "7   entropy            17            45      False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code and response for Question 5 here\n",
    "import pandas as pd\n",
    "\n",
    "#Creating a new random forest classifier to get the accuracy of more than 90%\n",
    "rfclassifier_new = RandomForestClassifier(criterion='entropy',max_features='log2',n_estimators=345,n_jobs=3,bootstrap=False)\n",
    "rfclassifier_new\n",
    "\n",
    "rfclassifier_new.fit(train,traincats)\n",
    "preds = rfclassifier_new.predict(validation)\n",
    "np.mean(preds == validationcats)\n",
    "\n",
    "# A new dataframe from which we can evaluate the accuracy. I made more than 2 values so that \n",
    "# i have a little bit more dataframe to find the accuracy from. \n",
    "\n",
    "table = {\n",
    "         'Criterion':['entropy','gini','gini','gini','entropy','entropy','entropy','entropy'] , \n",
    "         'max_features':[9,9,17,18,9,9,17,17] , \n",
    "         'n_estimators':[13,13,43,43,45,45,45,45] , \n",
    "         'bootstrap':[True,True,False,False,False,True,False,False]}\n",
    "table = pd.DataFrame(table)\n",
    "\n",
    "table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your response/code for Question 6 here (either a written response or reporting with code are fine)\n",
    "\n",
    "# I had to make a new classifier with different values to get more accuracy than 90%\n",
    "# After that while predicting the kernel had to be restarted everytime I wanted to test with different values.\n",
    "# Final accuracy came out to be 0.915. I beleive increasing the number of trees in the random forest without\n",
    "# using the dataset to prooduce each tree is the main reason for the better accuracy.\n",
    "# Also I noticed that there might be some weird reason on how kernel runs the code.\n",
    "# The same classifier value was giving different prediction everytime I ran it. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.915"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rfclassifier_new.predict(finaltest)\n",
    "np.mean(preds == finaltestcats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 7: Reflect on and explain any differences between your validation and final test accuracy scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your response here\n",
    "\n",
    "# I think changing the parameter according to the dataset did help to get more accuracy.\n",
    "# The algorithm can be tuned in based on what kind of dataset we have and how we want the prediction to happen. \n",
    "# I also found that having similar values in the dataframe helped to acheive more accuracy, where as changing just a \n",
    "# little bit of that values in the dataframe changes the accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
