{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Branded_Logo_CUDenver.PNG\" width=\"150\">\n",
    "\n",
    "## <center>CSCI 4580/5580 - Data Science – Spring 2022</center>\n",
    "<center>Lab 2: NLP</center><center><font color='red'>Deadline: February 25, 2022 - 11:59 PM</font></center><center>Total Points: 100</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Please note that this assignment must be done individually. By submitting this lab, you certify that this is your own work, your code will be checked against other submissions and resources using automatic tools. Everyone should be getting a hands on experience in this course. You are free to discuss course material with fellow students, and we encourage you to use Internet resources to aid your understanding, but the work you turn in, including all code and answers, must be your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "You need to submit a single .ipynb file on Canvas, names your-lastname_your-first-name.ipynb. For example, if your name is John Smith, you should name the file smith_john.ipynb.\n",
    "- Please do not include extra files such as the input datasets in your submission.\n",
    "- Answer Questions 1 - 18 in the designated cells. Please do not add or remove any cells. \n",
    "- Please download your submission file after submission and make sure it is not corrupted. Use the 'Run All' option from the 'Cell' menu to ensure all cells run without any issues. We will not be responsible for corrupted submissions and will not take a resubmission after the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need Help?\n",
    "If you need help with this lab, please email me at sundous.hussein@ucdenver.edu or come to my office hours. We also encourage you to ask your questions on the designated channel for the lab on Microsoft Teams. This way, you may receive assistance from your classmates that might’ve ran through the same issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we'll explore NLP with the Stanford Parsing suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE:\n",
    "The Stanford Parser requires the Ubuntu virtual machine that you created in lab 0. If you didn’t complete lab 0, please refer to the instructions there to install the required tools before continuing with this lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Analysis of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're going to use a parser to extract some \"facts\" from natural language. The text is from the simplified wikipedia site: http://simple.wikipedia.org. It has been filtered to find sentences about cats. Download the <b>cats.txt</b> file from Canvas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford Parser Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Stanford parser from Canvas and unpack it using the following command:\n",
    "\n",
    "<pre>tar xvzf stanfordparser.tar.gz</pre>\n",
    "\n",
    "and then move it to the /opt directory with\n",
    "\n",
    "<pre>sudo mv StanfordParser /opt</pre>\n",
    "\n",
    "It will be helpful to have links to the parser scripts from your bin directory. \n",
    "<pre>\n",
    "cd ~/bin\n",
    "ln -s /opt/StanfordParser/lexparser.sh lexparser.sh\n",
    "ln -s /opt/StanfordParser/lexparser-gui.sh lexparser-gui.sh\n",
    "ln -s /opt/StanfordParser/dependencyviewer/dependencyviewer.sh dependencyviewer.sh\n",
    "</pre>\n",
    "\n",
    "These files will be in your path the next time you login. You can logout from the start button at the top right of the VM window. Then log back in again.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a terminal window, type\n",
    "\n",
    "<pre>lexparser-gui.sh</pre> \n",
    "or alternatively \n",
    "<pre>~/bin/lexparser-gui.sh</pre>\n",
    " **NOTE: if java is not already installed, you can install it with:**\n",
    "  <pre>sudo apt install default-jre</pre>\n",
    " \n",
    "\n",
    "This brings up a GUI interface to the Stanford parser. To use it, click on \"Load Parser\" which brings up a file selection dialog. Navigate to\n",
    "\n",
    "<pre>/opt/StanfordParser/stanford-parser-3.4.1-models.jar</pre>\n",
    "\n",
    "and open it.\n",
    "\n",
    "Then you will see a list of parsers to use. Select\n",
    "\n",
    "<pre>englishPCFG.ser.gz</pre>\n",
    "\n",
    "You're now ready to parse some text!\n",
    "\n",
    "Click on the \"Load File\" button, and load the cats.txt file. Click on \"Parse\" to parse the current sentence (highlighted in yellow).\n",
    "\n",
    "### NOTE:\n",
    "The tags used by the parser are explained in more detail [here](https://gist.github.com/nlothian/9240750). The important parts of speech will be noun, verb, and subject. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 1) Generate two parse tree visualizations for any pair of sentences from cats.txt. The tree should show up in the bottom panel of the Stanford Parser when you click Parse. Screenshot the trees and insert the images below. Breifly reflect on the similarity/difference in structure between the two parse trees (for example: how are the parts of speech ordered, is one tree deeper/wider than the other, do the sentences seem like they should have similar/different trees but dont and why?) Make sure to submit the image files along with you notebook when you turn it in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Question 1 answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing to XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll parse the cats sentence file to XML. To do this, we'll make a customized version of the parser script. Copy the file:\n",
    "\n",
    "<pre>/opt/StanfordParser/lexparser.sh</pre>\n",
    "\n",
    "and save it as:\n",
    "\n",
    "<pre>/opt/StanfordParser/parsetoxml.sh</pre>\n",
    "\n",
    "Edit it so that its outputFormat is:\n",
    "\n",
    "<pre>-outputFormat \"xmlTree\"</pre>\n",
    "\n",
    "and add a new option:\n",
    "\n",
    "<pre>-outputFormatOptions \"xml\"</pre>\n",
    "\n",
    "and create an alias to parsetoxml.sh it in your ~/bin directory.\n",
    "<pre>cd ~/bin</pre>\n",
    "<pre>ln -s /opt/StanfordParser/parsetoxml.sh parsetoxml.sh</pre>\n",
    "\n",
    "Now run from your lab4 directory\n",
    "\n",
    "<pre>parsetoxml.sh cats.txt > cats.xml</pre>\n",
    "\n",
    "you're ready now to analyze the cats data. We'll use Python's built-in ElementTree parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now copy the cats.xml file out of the VM and into the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "parser = etree.XMLParser(recover=True)\n",
    "tree = etree.parse('cats.xml',parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the root of this tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=tree.getroot()\n",
    "root.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root[0].tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. we have found the first sentence. The xmlTree representation is a little tricky however, as POS tags are stored as attributes of nodes rather than node tags. To get to the actual root node, we need to dig a little deeper (and we'll use the second sentence which is a bit more conventional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root[1][0][0].attrib['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "going down one level gets us to the actual sentence node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=root[6][0][0][0]\n",
    "s.attrib['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and to get its children we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not too helpful, because the node types are hidden in the value attributes of these nodes. To see them, we can use a python anonymous function and map it over the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(map(lambda x: x.attrib['value'], s[:]))\n",
    "# or if you prefer list comprehensions: nodes = [x.attrib['value'] for x in s[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can find sentences starting with noun phrases containing a given noun. The final function supports a flexible syntax (similar to xpath) for locating elements of given type or attributes. A slash \"/\" is like a directory specifier, and defines a child node. A double slash \"//\" specifies any descendent, child, grandchild, great-grandchild, etc. The \"node[@value='NP']\" specifies a node with the given attribute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = s.findall(\"./node[@value='NP']//node[@value='NN']//leaf[@value='cat']\")\n",
    "agent[0].attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finds all the nodes starting with an 'NP' child of s, and having a 'NN' node above a leaf with 'cat' value.\n",
    "\n",
    "We can similarly look for a verb in a verb phrase under the root node:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = s.findall(\"./node[@value='VP']//node[@value='VBZ']//leaf[@value='is']\")\n",
    "verb[0].attrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting these together, we can discover sentences containing a given pair of (agent,action) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printnode(node):\n",
    "    for i in node.findall(\".//leaf\"):\n",
    "        print(\" \" + i.attrib['value']),\n",
    "    print('')\n",
    "\n",
    "def testnode(node, agent, action):\n",
    "    aa = node.findall(\"./node[@value='NP']//node[@value='NN']//leaf[@value='\"+agent+\"']\")\n",
    "    bb = node.findall(\"./node[@value='VP']//leaf[@value='\"+action+\"']\")\n",
    "    if (len(aa) > 0 and len(bb) > 0):\n",
    "        printnode(node)    \n",
    "\n",
    "def agentact(node, agent, action):\n",
    "    testnode(node, agent, action)\n",
    "    snodes = node.findall(\".//node[@value='S']\")\n",
    "    for snode in snodes:\n",
    "        testnode(snode, agent, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "title = 'cat'\n",
    "agentact(s, title, 'is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can apply the agentact function to all the sentences in the Wikipedia entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[agentact(nn[0][0][0], title, 'is') for nn in root]\n",
    "[] # hide the return bvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 2) Copy the code from the previous cell to the next cell and change the verb to something other than \"is\" that returns a few sentences. Can you find any sentences that share similar meaning based on their verb alone? Or completely different meaning? Write a breif sentence in a comment about what this could mean for an NLP model and the importance of having enough data.\n",
    "\n",
    "> Question 3) Finish the testnode2 function that returns sentences in which the given adjective (JJ) appears in the cell below, you will need to check for plural nouns (NNS) in addition to singular nouns, which requires a new search with a leaf node of \"cats\"instead of \"cat\". Try a few different adjectives (ex: wild, domestic, brown, etc.). Not all adjectives will return results, and you can always check the parse tree in the Stanford parser to check for available adjective-noun pairs. Do the sentences you see make sense? Now try the adjective \"dry\". Is cat/cats still the subject of the sentences you see returned, if not what is the subject of the sentence? Does this suggest anything to you about how the nuances of languages and how they should be modeled? Write 2-3 sentences in a comment about your observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add Question 2 code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testnode2(node, agent, modifier):\n",
    "    # Add Question 3 code here\n",
    "\n",
    "def agentact2(node, agent, modifier):\n",
    "    testnode2(node, agent, modifier)\n",
    "    snodes = node.findall(\".//node[@value='S']\")\n",
    "    for snode in snodes:\n",
    "        testnode2(snode, agent, modifier)\n",
    "        \n",
    "list(map(lambda nn: agentact2(nn[0][0][0], title, 'brown'), root))\n",
    "[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
